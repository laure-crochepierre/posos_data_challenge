{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "import enchant\n",
    "import re\n",
    "import sys\n",
    "import ipdb\n",
    "import unidecode\n",
    "\n",
    "from replacers import SpellingReplacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source path \n",
    "data_source_path = \"../../DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(data_source_path+'input_train.csv', sep=\";\")\n",
    "y = pd.read_csv(data_source_path+'output_train.csv', sep=\";\")\n",
    "\n",
    "features = X.columns\n",
    "targets = y['intention'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['﻿ID', 'question'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ID</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bonjour,  je m suis trompé de forum pour ma qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>est ce que le motilium me soulagera contre les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mon médecin m'a prescrit adenyl. au 2ème cache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce qu'il existe une forme adaptée aux enfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mon  medecin  me soigne  pour  une  rhino  pha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ID                                           question\n",
       "0    0  bonjour,  je m suis trompé de forum pour ma qu...\n",
       "1    1  est ce que le motilium me soulagera contre les...\n",
       "2    2  mon médecin m'a prescrit adenyl. au 2ème cache...\n",
       "3    3  Est-ce qu'il existe une forme adaptée aux enfa...\n",
       "4    4  mon  medecin  me soigne  pour  une  rhino  pha..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the list of medicaments\n",
    "medicaments = [x[:-1] for x in open(data_source_path+\"../DATA/medicaments.txt\", \"r\").readlines()]\n",
    "symptomes = [x[:-1] for x in open(data_source_path+\"symptomes.txt\", \"r\").readlines()]\n",
    "maladies = [x[:-1] for x in open(data_source_path+\"maladies.txt\", \"r\").readlines()]\n",
    "posologies = [\"mg\", \"ml\", \"ch\", \"g\", \"l\"]\n",
    "stop_words = stopwords.words('french')\n",
    "replacer = SpellingReplacer(dict_name='fr_FR')\n",
    "lemmatizer = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicateur d'avancement \n",
    "total = len(X['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of all the preprocessing done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost in order :\n",
    "- remove **ponctuation**\n",
    "- remove all **stop words**\n",
    "- test if word is in list of **drugs**\n",
    "- test if word is a **posology**\n",
    "- test if word is a **disease**\n",
    "- test if word is a **symptom**\n",
    "- test if word is an **hour**\n",
    "- test if word is an **age**\n",
    "- test if word is **ordinal number**\n",
    "- replace a maximum of **typo mistakes** with pyenchant : \n",
    "    from a list of suggestions, take the most probable one, \n",
    "    test if it is a stop word \n",
    "    replace the word only if the most probable suggestion is more than 1 letter \n",
    "- **lemmatizing** of words \n",
    "- remove **accents**\n",
    "- remove **short words** of less than 2 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(word):\n",
    "    word = word.lower()\n",
    "    heure_re = r'[0-9]{1,2}h[0-9]{,2}$'\n",
    "    ordinal_re = r'[0-9]+(er|ème|ère|eme|ere)$'\n",
    "    age_re = r'[0-9]+(ans|an)$'\n",
    "    posologie_re = r'[0-9]+(mg|g|l|ml|ch|milligramme|milligrammes|milligramm)$'\n",
    "    if word in medicaments:\n",
    "        word = \"medicament\" #\"<MEDICAMENT>\" \n",
    "        count['medicaments']+=1\n",
    "    elif word in posologies: \n",
    "        word = \"posologie\" #\"<POSOLOGIE>\"\n",
    "        count['posologies']+=1\n",
    "    elif re.match(posologie_re,word):\n",
    "        word = \"posologie\" #\"<POSOLOGIE>\" \n",
    "        count['posologies']+=1\n",
    "    elif word in maladies:\n",
    "        word = \"maladie\" #\"<MALADIE>\"\n",
    "        count['maladies']+=1\n",
    "    elif word in symptomes:\n",
    "        word = \"symptome\" #\"<SYMPTOME>\" \n",
    "        count['symptomes']+=1\n",
    "    elif re.match(heure_re,word):\n",
    "        word = \"heure\" #\"<HEURE>\" \n",
    "        count['heures']+=1\n",
    "    elif re.match(age_re,word):\n",
    "        word = \"age\" #\"<AGE>\" \n",
    "        count['ages']+=1\n",
    "    elif re.match(ordinal_re,word):\n",
    "        word = \"ordinal\" #\"<ORDINAL>\"\n",
    "        count['ordinal']+=1\n",
    "    else:\n",
    "        suggestion = replacer.replace(word)\n",
    "        if suggestion != word: \n",
    "            count['corrections']+=1\n",
    "            valid_suggestion = re.sub(r'[^\\w]', ' ', suggestion).split()\n",
    "            if valid_suggestion[len(valid_suggestion)-1] not in stop_words:\n",
    "                word = valid_suggestion[len(valid_suggestion)-1].lower()\n",
    "    return word\n",
    "\n",
    "def preprocess(row):\n",
    "    sentence = re.sub(r'[^\\w]', ' ', row['question'])\n",
    "    word_list = [clean(word) for word in sentence.split() if (word not in stop_words)]\n",
    "    lemma_list = [unidecode.unidecode(word.lemma_) for word in lemmatizer(' '.join(word for word in word_list))]\n",
    "    preprocessed_sentence = ' '.join(word for word in lemma_list if( len(word)>2 and not re.match( r'^[0-9]*$',word)) )\n",
    "    \n",
    "    if row['﻿ID']%100 == 0:\n",
    "        print(\" row {} / {}\".format(row['﻿ID'], total),end='\\r')\n",
    "    return preprocessed_sentence\n",
    "\n",
    "def output_format(row):\n",
    "    return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maladies': 1833, 'ordinal': 180, 'posologies': 649, 'corrections': 6652, 'medicaments': 9942, 'ages': 40, 'symptomes': 311, 'heures': 169}\n"
     ]
    }
   ],
   "source": [
    "count = {'medicaments' : 0,'posologies': 0,'maladies': 0,'symptomes' :0, \"corrections\": 0, \"ages\":0, \"heures\":0, \"ordinal\":0}\n",
    "X_sub = X.iloc[:10]\n",
    "X_clean = X.apply(preprocess, axis = 1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prendre medicament fin premier plaquette premier foi copain pilule donc bien efficace des debut symptome poitrine impression peu grossir aussi plaire maladie bas venter devoir minkiete simplement periode adaptation'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean.to_csv(data_source_path+'clean_data/cleaning_plus_lemmatizing_input_train.csv', sep=';', header = ['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
